#!/bin/bash
DATESTAMP=`date +'%y%m%d%H%M%S'`
export INPUT_FILES_DIR_UNPACKED=/root/datasets/bert_pretraining/training
export INPUT_FILES_DIR_PACKED=/root/datasets/train/packed_data_500
export EVAL_FILES_DIR=/root/datasets/mlperf_bert_eval_dataset
export OUTPUT_DIR=/tmp/bert_pretrain/phase_2
export LOG_DIR=/tmp/bert_pretrain/phase_2
export INITIAL_CHECKPOINT=/root/datasets/MLPerf_BERT_checkpoint/model.ckpt-28252
export BERT_CONFIG_DIR=/root/datasets/MLPerf_BERT_checkpoint
export TRAIN_BATCH_SIZE=14
export EVAL_BATCH_SIZE=125
export MAX_EVAL_STEPS=10
export NUM_DIST_EVAL_WORKERS=8
export TRAIN_STEPS=6700
export LEARNING_RATE=0.00035
export LAMB_BETA_1=0.9
export LAMB_BETA_2=0.999
export EPSILON=1e-06
export LAMB_WEIGHT_DECAY_RATE=0.01
export LAMB_LEARNING_RATE_DECAY_POLY_POWER=1.0
export NUM_ACCUMULATION_STEPS=4
export SAMPLES_START_EVAL=0
export SAVE_CHECKPOINTS_STEPS=335
export PACKED_DATA=True
export USE_HOROVOD=True
export HLS_TYPE="OCP1"
export NUM_WORKERS_TOTAL=8
export RUN_TPC_FUSER=True
export MPI_TCP_INCLUDE=enp24s0f0
export TF_CPU_RUNTIME_FALLBACK=forbid
export TF_HCCL_MEMORY_ALLOWANCE_MB=1536
export HABANA_INITIAL_WORKSPACE_SIZE_MB=4600
export CPU_BIND_TYPE=cpu
export USE_LIGHTWEIGHT_CHECKPOINT=True
export DO_TRAIN=True
export DO_EVAL=True
