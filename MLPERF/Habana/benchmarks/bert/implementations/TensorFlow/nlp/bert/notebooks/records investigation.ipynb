{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# imports ...\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import collections\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/gdn-workloads/ihubara/tfrecord_dir_packed'\n",
    "list_ = ! ls /mnt/gdn-workloads/ihubara/tfrecord_dir_packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0,
     14,
     31
    ]
   },
   "outputs": [],
   "source": [
    "def record2dict(record:bytes) -> collections.OrderedDict:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(record.numpy())\n",
    "    result = collections.OrderedDict()\n",
    "    feature = example.feature.feature\n",
    "    result['input_ids'] = np.array(feature['input_ids'].int64_list.value)\n",
    "    result['input_mask'] = np.array(feature['input_mask'].int64_list.value)\n",
    "    result['segment_ids'] = np.array(feature['segment_ids'].int64_list.value)\n",
    "    result['masked_lm_positions'] = np.array(feature['masked_lm_positions'].int64_list.value)\n",
    "    result['masked_lm_ids'] = np.array(feature['masked_lm_ids'].int64_list.value)\n",
    "    result['masked_lm_weights'] = np.array(feature['masked_lm_weights'].float_list.value)\n",
    "    result['next_sentence_labels'] = np.array(feature['next_sentence_labels'].int64_list.value)\n",
    "    return result\n",
    "\n",
    "def packed_record2dict(record:bytes) -> collections.OrderedDict:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(record.numpy())\n",
    "    result = collections.OrderedDict()\n",
    "    feature = example.feature.feature\n",
    "    result['input_ids'] = np.array(feature['input_ids'].int64_list.value)\n",
    "    result['input_mask'] = np.array(feature['input_mask'].int64_list.value)\n",
    "    result['segment_ids'] = np.array(feature['segment_ids'].int64_list.value)\n",
    "    result['positions'] = np.array(feature['positions'].int64_list.value)\n",
    "    result['masked_lm_positions'] = np.array(feature['masked_lm_positions'].int64_list.value)\n",
    "    result['masked_lm_ids'] = np.array(feature['masked_lm_ids'].int64_list.value)\n",
    "    result['masked_lm_weights'] = np.array(feature['masked_lm_weights'].float_list.value)\n",
    "    result['next_sentence_positions'] = np.array(feature['next_sentence_positions'].int64_list.value)\n",
    "    result['next_sentence_labels'] = np.array(feature['next_sentence_labels'].int64_list.value)\n",
    "    result['next_sentence_weights'] = np.array(feature['next_sentence_weights'].float_list.value)\n",
    "    return result\n",
    "\n",
    "def get_next_sentence_weights(record:bytes) -> np.ndarray:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(record.numpy())\n",
    "    feature = example.feature.feature\n",
    "    return np.array(feature['next_sentence_weights'].float_list.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Count number of records.\n",
    "'''\n",
    "counter = 0\n",
    "for file in tqdm(list_):\n",
    "    records = tf.data.TFRecordDataset(os.path.join(path, file))\n",
    "    records = [record for record in records]\n",
    "    counter += len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Compute average of number samples per record (avg_seq_per_pack).\n",
    "'''\n",
    "pbar = tqdm(total=4746826)\n",
    "\n",
    "pack_numbers = []\n",
    "for file in list_:\n",
    "    records = tf.data.TFRecordDataset(os.path.join(path, file))\n",
    "    for record in records:\n",
    "        next_sentence_weights = get_next_sentence_weights(record)\n",
    "        pack_numbers.append(next_sentence_weights.sum())\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Before packing:\n",
    "    len(input_ids) - 512, list of token ids where (101 - start, 102 - end, 103 - mask), padded to 512 with zeros.\n",
    "    len(input_mask) - 512, 111...111000...000, where the number of ones corresponds to the effective sample length, padded to 512 with zeros.\n",
    "    len(segment_ids) - 512, 000...000111...111000...000, where first zeros correspond to the first sentence, ones to second sentence, \n",
    "                            and  padded to 512 with zeros.\n",
    "    len(masked_lm_positions) - 76, positions of masked tokens (103),  padded to 76 with zeros.\n",
    "    len(masked_lm_ids) - 76, token ids of masked tokens,  padded to 76 with zeros.\n",
    "    len(masked_lm_weights) - 76, 111...111000...000, number of ones equals to number of masked tokens.\n",
    "    len(next_sentence_labels) - 1, 0 or 1, where 1 if sentence 2 is the next sentence of sentence 1.\n",
    "\n",
    "\n",
    "After packing:\n",
    "    len(packed_input_ids) - 512, list of token ids where (101 - start, 102 - end, 103 - mask), padded to 512 with zeros.\n",
    "                                 If we have 2 samples packed: 101,...,102,...,102,101,...,102,...,102,0...0\n",
    "                                 where 101,...,102 first sentence, ,...,102 second sentence,\n",
    "                                 101,...,102 third sentence and ,...,102 forth sentence.\n",
    "    len(packed_input_mask) - 512, 111...111222...222000...000, where the number of ones corresponds to the first sample length, \n",
    "                                  and the number of twos corresponds to the second sample length. (If there are 3 samples 1...12...23...30...0.)\n",
    "    len(packed_segment_ids) - 512, 000...000111...111000...000111...111000...000 where 000...000111...111 the first and the second samples,\n",
    "                                   padded to 512 with zeros.\n",
    "    len(packed_positions) - 512, 0,1,2,3,...,<length of first sample> - 1,0,1,2,3,...,<length of second sample> - 1,0,0,...,0\n",
    "    len(packed_masked_lm_positions) - 79, positions of masked tokens (103), padded to 79 with zeros.\n",
    "    len(packed_masked_lm_ids) - 79, token ids of masked tokens, padded to 76 with zeros.\n",
    "    len(packed_masked_lm_weights) - 79, 111...111222...222000...000 where 111...111 corresponds to first sample\n",
    "                                        and 222...222 to second. (If there are 3 samples 1...12...23...30...0.)\n",
    "    len(packed_next_sentence_positions) - 3, <position of first sample>,<position of second sample>,0 (corresponds to 101 positions)\n",
    "    len(packed_next_sentence_labels) - 3, 0 or 1, where 1 if sentence 2 is the next sentence of sentence 1.\n",
    "    len(packed_next_sentence_weights) - 3, 110 (If there are 3 samples 111.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Data packed from 30 tfrecords has 4746826 records (multi-samples).\n",
    "Total number of samples in records is 9648228.\n",
    "\n",
    "avg_seq_per_pack = 2.0325640754474676\n",
    "\n",
    "\n",
    "Coverage during training: ('batch size'=14, 'number of accumulation steps'=4, 'number of cards'=8, 'number of training steps'=6365)\n",
    "14*4*8*6365 / 9648228 * 100 = 29.55%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = tf.data.TFRecordDataset(os.path.join(path, list_[0]))\n",
    "dict_ = record2dict(next(iter(records)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,   6,   7,   8,  14,  22,  31,  36,  37,  53,  55,  59,  62,\n",
       "        73,  87, 101, 102, 105, 120, 130, 131, 133, 135, 161, 162, 164,\n",
       "       168, 171, 180, 198, 205, 219, 230, 235, 237, 238, 241, 249, 251,\n",
       "       263, 270, 271, 288, 289, 293, 300, 303, 304, 310, 313, 315, 320,\n",
       "       321, 324, 328, 347, 353, 356, 366, 369, 378, 384, 390, 395, 403,\n",
       "       404, 407, 431, 448, 451, 456, 465, 484, 491, 493, 495, 507,   0,\n",
       "         0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_['masked_lm_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10578,  2003,  1037,  7960,  1010,  2094, 11842,  4856,  1998,\n",
       "        2062,  1010,  1011,  2018, 11762,  7170,  1996, 12731,  4221,\n",
       "        2029, 15185,  6590,  1006,  3126,  2988,  1010,  1037,  2006,\n",
       "        2340, 15185,  1024,  1024,  1996,  1012,  2470,  3919,  3934,\n",
       "        2752,  1998,  1999,  2047,  8324,  1010,  2015,  1010,  2464,\n",
       "        3934,  4981,  1998,  1038,  1012,  2504,  1006,  4816,  3330,\n",
       "        5992,  1006,  5992,  4806,  1007,  1997,  4513,  1997,  2008,\n",
       "        2007,  2095,  1010,  1998,  1997,  8065,  2048,  1998,  5179,\n",
       "        2627,  4249,  1038,  1055,  2089,     0,     0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_['masked_lm_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_['masked_lm_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
