#!/bin/bash
DATESTAMP=`date +'%y%m%d%H%M%S'`
export INPUT_FILES_DIR_UNPACKED=/root/datasets/tensorflow_bert/unpacked_data
export INPUT_FILES_DIR_PACKED=/root/datasets/tensorflow_bert/packed_data_500
export EVAL_FILES_DIR=/root/datasets/tensorflow_bert/eval_dataset
export INITIAL_CHECKPOINT=/root/datasets/tensorflow_bert/checkpoint/model.ckpt-28252
export BERT_CONFIG_DIR=/root/datasets/tensorflow_bert/checkpoint
export OUTPUT_DIR=/tmp/bert_pretrain/phase_2
export LOG_DIR=/tmp/bert_pretrain/phase_2
export TRAIN_BATCH_SIZE=28
export EVAL_BATCH_SIZE=125
export MAX_EVAL_STEPS=10
export NUM_DIST_EVAL_WORKERS=8
export TRAIN_STEPS=6700
export WARMUP_STEPS=0
export LEARNING_RATE=0.000425
export LAMB_BETA_1=0.9
export LAMB_BETA_2=0.999
export EPSILON=1e-06
export LAMB_WEIGHT_DECAY_RATE=0.01
export LAMB_LEARNING_RATE_DECAY_POLY_POWER=1.0
export NUM_ACCUMULATION_STEPS=2
export SAMPLES_START_EVAL=0
export SAVE_CHECKPOINTS_STEPS=335
export PACKED_DATA=True
export USE_HOROVOD=True
export HLS_TYPE="HLS2"
export NUM_WORKERS_TOTAL=8
export TF_CPU_RUNTIME_FALLBACK=forbid
export TF_HCCL_MEMORY_ALLOWANCE_MB=1536
export HABANA_INITIAL_WORKSPACE_SIZE_MB=4600
export CPU_BIND_TYPE=cpu
export USE_LIGHTWEIGHT_CHECKPOINT=True
export DO_TRAIN=True
export DO_EVAL=True
export USE_ASYNC_CHECKPOINTING=True
export EXPERIMENTAL_SLACK=True
export SIGNALING_FROM_GRAPH=0

unset MPI_TCP_INCLUDE
