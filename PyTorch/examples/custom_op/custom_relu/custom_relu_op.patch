diff --git a/PyTorch/computer_vision/classification/torchvision/model/resnet.py b/PyTorch/computer_vision/classification/torchvision/model/resnet.py
index 0daee4730..3ddb9f7c7 100644
--- a/PyTorch/computer_vision/classification/torchvision/model/resnet.py
+++ b/PyTorch/computer_vision/classification/torchvision/model/resnet.py
@@ -3,7 +3,14 @@
 import torch
 import torch.nn as nn
 from .utils import load_state_dict_from_url
-
+import sys
+import os
+custom_dir = os.path.realpath(__file__)
+custom_len = custom_dir.rfind('/')
+base_dir = custom_dir[:custom_len]
+custom_path = base_dir + '/../../../../examples/'
+sys.path.insert(0, custom_path)
+from custom_op.custom_relu import CustomReLU
 
 __all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',
            'resnet152', 'resnext50_32x4d', 'resnext101_32x4d', 'resnext101_32x8d',
@@ -50,7 +57,7 @@ class BasicBlock(nn.Module):
         # Both self.conv1 and self.downsample layers downsample the input when stride != 1
         self.conv1 = conv3x3(inplanes, planes, stride)
         self.bn1 = norm_layer(planes)
-        self.relu = nn.ReLU(inplace=True)
+        self.relu = CustomReLU() # nn.ReLU is replaced by CustomReLU
         self.conv2 = conv3x3(planes, planes)
         self.bn2 = norm_layer(planes)
         self.downsample = downsample
@@ -92,7 +99,7 @@ class Bottleneck(nn.Module):
         self.bn2 = norm_layer(width)
         self.conv3 = conv1x1(width, planes * self.expansion)
         self.bn3 = norm_layer(planes * self.expansion)
-        self.relu = nn.ReLU(inplace=True)
+        self.relu = CustomReLU() # nn.ReLU is replaced by CustomReLU
         self.downsample = downsample
         self.stride = stride
 
@@ -143,7 +150,7 @@ class ResNet(nn.Module):
         self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,
                                bias=False)
         self.bn1 = norm_layer(self.inplanes)
-        self.relu = nn.ReLU(inplace=True)
+        self.relu = CustomReLU() # nn.ReLU is replaced by CustomReLU
         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
         self.layer1 = self._make_layer(block, 64, layers[0])
         self.layer2 = self._make_layer(block, 128, layers[1], stride=2,
diff --git a/PyTorch/computer_vision/classification/torchvision/train.py b/PyTorch/computer_vision/classification/torchvision/train.py
index d4efe3a20..396cf4588 100644
--- a/PyTorch/computer_vision/classification/torchvision/train.py
+++ b/PyTorch/computer_vision/classification/torchvision/train.py
@@ -3,9 +3,6 @@
 
 from __future__ import print_function
 
-#Import local copy of the model only for ResNext101_32x4d
-#which is not part of standard torchvision package.
-import model as resnet_models
 import datetime
 import os
 import time
@@ -270,6 +267,7 @@ def main(args):
     if args.run_lazy_mode:
         os.environ["PT_HPU_LAZY_MODE"] = "1"
     if args.is_hmp:
+        assert False, "Integration with HMP for mixed mode training is not yet supported for custom op"
         from habana_frameworks.torch.hpex import hmp
         hmp.convert(opt_level=args.hmp_opt_level, bf16_file_path=args.hmp_bf16,
                     fp32_file_path=args.hmp_fp32, isVerbose=args.hmp_verbose)
@@ -291,6 +289,10 @@ def main(args):
         from habana_frameworks.torch.utils.library_loader import load_habana_module
         load_habana_module()
 
+    #Import local copy of the model only for ResNext101_32x4d
+    #which is not part of standard torchvision package.
+    import model as resnet_models
+
     torch.manual_seed(args.seed)
 
     if args.deterministic:
@@ -331,7 +333,7 @@ def main(args):
     print("Creating model")
     #Import only resnext101_32x4d from a local copy since torchvision
     # package doesn't support resnext101_32x4d variant
-    if 'resnext101_32x4d' in args.model:
+    if 'resnext101_32x4d' in args.model or 'resnet50' in args.model:
         model = resnet_models.__dict__[args.model](pretrained=args.pretrained)
     else:
         model = torchvision.models.__dict__[
@@ -440,7 +442,7 @@ def main(args):
                 permute_params(model_without_ddp, False, args.run_lazy_mode)
                 # Use this model only to copy the state_dict of the actual model
                 copy_model = resnet_models.__dict__[args.model](
-                    pretrained=args.pretrained) if 'resnext101_32x4d' in args.model else torchvision.models.__dict__[args.model](pretrained=args.pretrained)
+                    pretrained=args.pretrained) if 'resnext101_32x4d' in args.model or 'resnet50' in args.model else torchvision.models.__dict__[args.model](pretrained=args.pretrained)
 
                 copy_model.load_state_dict(model_without_ddp.state_dict())
                 # Permute the weight momentum buffer before saving in checkpoint
