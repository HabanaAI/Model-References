diff --git a/PyTorch/computer_vision/classification/torchvision/model/resnet.py b/PyTorch/computer_vision/classification/torchvision/model/resnet.py
index 0daee4730..fc2734699 100644
--- a/PyTorch/computer_vision/classification/torchvision/model/resnet.py
+++ b/PyTorch/computer_vision/classification/torchvision/model/resnet.py
@@ -3,6 +3,14 @@
 import torch
 import torch.nn as nn
 from .utils import load_state_dict_from_url
+import sys
+import os
+custom_dir = os.path.realpath(__file__)
+custom_len = custom_dir.rfind('/')
+base_dir = custom_dir[:custom_len]
+custom_path = base_dir + '/../../../../examples/'
+sys.path.insert(0, custom_path)
+from custom_op.custom_relu import CustomReLU
 
 
 __all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',
@@ -50,7 +58,7 @@ class BasicBlock(nn.Module):
         # Both self.conv1 and self.downsample layers downsample the input when stride != 1
         self.conv1 = conv3x3(inplanes, planes, stride)
         self.bn1 = norm_layer(planes)
-        self.relu = nn.ReLU(inplace=True)
+        self.relu = CustomReLU() # nn.ReLU is replaced by CustomReLU
         self.conv2 = conv3x3(planes, planes)
         self.bn2 = norm_layer(planes)
         self.downsample = downsample
@@ -92,7 +100,7 @@ class Bottleneck(nn.Module):
         self.bn2 = norm_layer(width)
         self.conv3 = conv1x1(width, planes * self.expansion)
         self.bn3 = norm_layer(planes * self.expansion)
-        self.relu = nn.ReLU(inplace=True)
+        self.relu = CustomReLU() # nn.ReLU is replaced by CustomReLU
         self.downsample = downsample
         self.stride = stride
 
@@ -143,7 +151,7 @@ class ResNet(nn.Module):
         self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,
                                bias=False)
         self.bn1 = norm_layer(self.inplanes)
-        self.relu = nn.ReLU(inplace=True)
+        self.relu = CustomReLU() # nn.ReLU is replaced by CustomReLU
         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
         self.layer1 = self._make_layer(block, 64, layers[0])
         self.layer2 = self._make_layer(block, 128, layers[1], stride=2,
diff --git a/PyTorch/computer_vision/classification/torchvision/train.py b/PyTorch/computer_vision/classification/torchvision/train.py
index 790c66717..5cacedb60 100644
--- a/PyTorch/computer_vision/classification/torchvision/train.py
+++ b/PyTorch/computer_vision/classification/torchvision/train.py
@@ -17,9 +17,6 @@
 import torchvision
 from torchvision import transforms
 
-#Import local copy of the model only for ResNext101_32x4d
-#which is not part of standard torchvision package.
-import model as resnet_models
 import habana_frameworks.torch.core as htcore
 from data_loaders import build_data_loader
 
@@ -257,5 +254,9 @@ def main(args):
             assert False, "Could Not import habana dataloader package"
 
+    #Import local copy of the model only for ResNext101_32x4d
+    #which is not part of standard torchvision package.
+    import model as resnet_models
+
     # Enable hpu dynamic shape
     if args.device == 'hpu':
             try:
@@ -340,7 +336,8 @@ def main(args):
     print("Creating model")
     #Import only resnext101_32x4d from a local copy since torchvision
     # package doesn't support resnext101_32x4d variant
-    if 'resnext101_32x4d' in args.model:
+    #using local copy of resnet50 to showcase custom op usage
+    if 'resnext101_32x4d' in args.model or 'resnet50' in args.model:
         model = resnet_models.__dict__[args.model](pretrained=args.pretrained)
     else:
         model = torchvision.models.__dict__[
