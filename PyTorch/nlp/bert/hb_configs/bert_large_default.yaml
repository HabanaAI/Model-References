###############################################################################
# Copyright (C) 2020-2021 Habana Labs, Ltd. an Intel Company
###############################################################################

model: "bert"
env_variables:

parameters:
  # Model name, possible values: base, large
  model_name_or_path: large
  # Training sub-command, possible values: finetuning, pretraining
  command: finetuning
  # Training mode: eager or graph
  mode: graph
  # Task_name, possible values: mrpc, squad, bookswiki
  task_name: squad
  data_type: bf16
  num_train_epochs: 2
  store_true:
    - "do_eval"

  dataset_parameters:
    mrpc:
      data_type_parameters:
        bf16:
          batch_size: 64
        fp32:
          batch_size: 32
      max_seq_length: 128
      learning_rate: 2e-5
      data_dir: "/software/data/pytorch/transformers/glue_data/"

    squad:
      data_type_parameters:
        bf16:
          batch_size: 24
        fp32:
          batch_size: 12
      max_seq_length: 384
      learning_rate: 3e-5
      data_dir: "/software/data/pytorch/transformers/Squad"

    bookswiki:
      data_type_parameters:
        bf16:
          batch_size:
            - 64
            - 8
        fp32:
          batch_size:
            - 32
            - 8
      data_dir: "/software/data/pytorch/bert_pretraining/hdf5_lower_case_1_seq_len_128/wikicorpus_en,/software/data/pytorch/bert_pretraining/hdf5_lower_case_1_seq_len_512/wikicorpus_en"
