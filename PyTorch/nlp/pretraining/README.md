# Table of Contents
- [NLP Pre-training for PyTorch](#bert-for-pytorch)

# NLP Pre-training for PyTorch

This folder contains scripts to pre-train language models on Habana Gaudi<sup>TM</sup> device to achieve state-of-the-art accuracy. Please visit [this page](https://developer.habana.ai/resources/habana-training-models/#performance) for performance information.

For more information about training deep learning models on Gaudi, visit [developer.habana.ai](https://developer.habana.ai/resources/).

The demos included in this release are as follows:

## BERT Pre-Training
- BERT Large pre-training on Wikipedia BookCorpus and Wiki dataset

The demo script is a wrapper for respective python training scripts. Additional environment variables are used in training scripts in order to achieve optimal results for each workload.

